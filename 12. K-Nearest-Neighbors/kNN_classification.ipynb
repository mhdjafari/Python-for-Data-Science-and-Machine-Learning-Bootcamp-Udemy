{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN implementation for a Classification Problem\n",
    "The model for kNN is the entire dataset. When a prediction is required for a unseen data instance, the kNN algorithm will search through the training dataset for the k-most similar instances. The prediction attribute of the most similar instances is summarized and returned as the prediction for the unseen data.\n",
    "\n",
    "The similarity measure is dependent on the type of data. For real-valued data, the Euclidean distance can be used.\n",
    "Other types of data such as categorical or binary , other distance measures could be used.\n",
    "\n",
    "In the case of regression problems, the average of the predicted attribute may be returned. In the case of classification problems, the most prevalent class may be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Data and make them to train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(filename, split, trainingSet = [], testSet = []):\n",
    "    with open(filename) as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for x in range(len(dataset) - 1):\n",
    "            for y in range(4):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9, 3.0, 1.4, 0.2, 'Iris-setosa'], [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'], [4.6, 3.1, 1.5, 0.2, 'Iris-setosa']]\n",
      "[[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'], [5.0, 3.6, 1.4, 0.2, 'Iris-setosa'], [4.8, 3.0, 1.4, 0.1, 'Iris-setosa']]\n"
     ]
    }
   ],
   "source": [
    "trainingSet = []\n",
    "testSet = []\n",
    "a = loadDataset('iris.data.txt', 0.66, trainingSet, testSet)\n",
    "print(trainingSet[0:3])\n",
    "print(testSet[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "In order to make predictions we need to calculate the similarity between any two given data instances. In this case it is the Euclidean distance which is the square root of the sum of the squared differences between the two array of numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(instance1, instance2, length):  # length : length of the array you want the distance to be calculated\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += np.power((instance1[x] - instance2[x]), 2)\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4641016151377544\n"
     ]
    }
   ],
   "source": [
    "data1 = [2, 2, 2, 'a']\n",
    "data2 = [4, 4, 4, 'b']\n",
    "euc_dist = euclideanDistance(data1, data2, 3)\n",
    "print(euc_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbors\n",
    "Now that we have a similarity measure, we can use it to collect the k-most similar instances for a given unseen instance.\n",
    "So, in principle we are calculating the distances of all instances of the train set with the one instance of test set (unseen set) and selecting a subset with the smallest distance values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance) - 1 # removing the response column from the array\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist)) # a tuple of training set observation and the distance.\n",
    "    distances.sort(key = operator.itemgetter(1)) # sort the tuple by the value (ascending) as the input arg is 1\n",
    "    neighbors = []\n",
    "    for x in range(k): # k-nearest neighbors\n",
    "        neighbors.append(distances[x][0])  # just the train instance and not the distance\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 4, 4, 'b']]\n"
     ]
    }
   ],
   "source": [
    "trainSet = [[2, 2, 2, 'a'], [4, 4, 4, 'b']]\n",
    "testInstance = [5, 5, 5]\n",
    "k = 1\n",
    "neighbors = getNeighbors(trainSet, testInstance, 1)\n",
    "print(neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response\n",
    "Once we have located the most similar neighbors for a test instance, the next task is to devise a predicted response based on these neighbors. We can do it by allowing each neighbor to vote for their class attribute and take majority vote as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1] # extracting the class value of the neighbors\n",
    "        if response not in classVotes:\n",
    "            classVotes[response] = 1\n",
    "        else:\n",
    "            classVotes[response] += 1\n",
    "    sortedVotes = sorted(classVotes.items(), key = operator.itemgetter(1), reverse=True) # descending by values\n",
    "    return sortedVotes[0][0] # 1st tuple and 1st item which is the response variable (with highest vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "neighbors = [[2, 2, 2, 'a'], [1, 1, 1, 'a'], [3, 3, 3, 'c']]\n",
    "response = getResponse(neighbors)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(testSet))) * 100.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "testSet = [[1, 1, 1, 'a'], [2, 2, 2, 'a'], [3, 3, 3, 'b']]\n",
    "predictions = ['a', 'a', 'a']\n",
    "accuracy = getAccuracy(testSet, predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-setosa' Actual = 'Iris-setosa'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-versicolor'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-versicolor' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Predicted = 'Iris-virginica' Actual = 'Iris-virginica'\n",
      "Accuracy: 91.30434782608695%\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    trainingSet = []\n",
    "    testSet = []\n",
    "    split = 0.67\n",
    "    loadDataset('iris.data.txt', split, trainingSet, testSet)\n",
    "    \n",
    "    predictions = []\n",
    "    k = 10\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        print('Predicted = ' +repr(result)+ ' Actual = ' +repr(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ' +repr(accuracy)+ '%')\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
